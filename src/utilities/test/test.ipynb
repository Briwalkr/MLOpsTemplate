{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "kv=ws.get_default_keyvault()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prerequisite\n",
    "If you use the provision feature, then just need a workspace ws object\n",
    "If you need to create the cluster manually\n",
    "    1. Create a service principal and secret (SP)\n",
    "    2. Provision an ADX cluster and create a DB\n",
    "    3. Add the SP to be contributor of the cluster\n",
    "    4. pip install following packages: pip install --upgrade azure-mgmt-kusto azure-kusto-ingest azure-kusto-data azure-identity \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provisioning resource\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code provision ADX cluster and register neccessary information at the workspace's keyvault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option to set parameters to a custom ADX cluster\n",
    "# from monitoring import KV_SP_ID, KV_SP_KEY, KV_ADX_DB, KV_ADX_URI, KV_TENANT_ID\n",
    "# tenant_id = \"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "# #Application ID\n",
    "# client_id = \"af883abf-89dd-4889-bdb3-1ee84f68465e\"\n",
    "# #Client Secret, set it at your WS' keyvault with key name same as your client_id\n",
    "# client_secret = kv.get_secret(client_id)\n",
    "# subscription_id = \"0e9bace8-7a81-4922-83b5-d995ff706507\"\n",
    "\n",
    "# cluster_uri = \"https://adx02.westus2.kusto.windows.net\" #URL of the ADX Cluster\n",
    "# kv.set_secret(KV_SP_ID,client_id)\n",
    "# kv.set_secret(KV_SP_KEY,client_secret)\n",
    "# kv.set_secret(KV_ADX_DB,\"db01\")\n",
    "# kv.set_secret(KV_ADX_URI,cluster_uri)\n",
    "# kv.set_secret(KV_TENANT_ID,tenant_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monitoring.management import provision\n",
    "provision(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'ws'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nserafino\\Documents\\Other\\github-mlops\\GitHub\\src\\utilities\\test\\test.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000008?line=4'>5</a>\u001b[0m sample_pd_data[\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sample_pd_data[\u001b[39m'\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000008?line=5'>6</a>\u001b[0m sample_pd_data\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m'\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000008?line=7'>8</a>\u001b[0m online_collector \u001b[39m=\u001b[39m Online_Collector(table_name,ws\u001b[39m=\u001b[39;49mws)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'ws'"
     ]
    }
   ],
   "source": [
    "from monitoring.data_collector import Online_Collector\n",
    "table_name = \"isd_weather_test4\" #new dataset\n",
    "\n",
    "sample_pd_data = pd.read_parquet(\"data/test_data.parquet\").head(10)\n",
    "sample_pd_data['timestamp'] = sample_pd_data['datetime']\n",
    "sample_pd_data.drop(['datetime'], inplace=True, axis=1)\n",
    "\n",
    "online_collector = Online_Collector(table_name,ws=ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://adx02.westus2.kusto.windows.net'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_collector.cluster_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Online_Collector' object has no attribute 'stream_collect_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nserafino\\Documents\\Other\\github-mlops\\GitHub\\src\\utilities\\test\\test.ipynb Cell 11'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000010?line=0'>1</a>\u001b[0m online_collector\u001b[39m.\u001b[39;49mstream_collect_df(sample_pd_data)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Online_Collector' object has no attribute 'stream_collect_df'"
     ]
    }
   ],
   "source": [
    "online_collector.stream_collect_df(sample_pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_collector.batch_collect(sample_pd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Ingestion and Real Time Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'ws'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nserafino\\Documents\\Other\\github-mlops\\GitHub\\src\\utilities\\test\\test.ipynb Cell 15'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000013?line=0'>1</a>\u001b[0m \u001b[39m# Ingest streaming data  asynchronously with internal buffering mechanism to lower impact to main scoring thread\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000013?line=1'>2</a>\u001b[0m streaming_table_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstreaming_test\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000013?line=2'>3</a>\u001b[0m streaming_collector \u001b[39m=\u001b[39m Online_Collector(streaming_table_name,ws\u001b[39m=\u001b[39;49mws)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000013?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000013?line=5'>6</a>\u001b[0m streaming_collector\u001b[39m.\u001b[39mstart_logging_df(buffer_time\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'ws'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ingest streaming data  asynchronously with internal buffering mechanism to lower impact to main scoring thread\n",
    "streaming_table_name=\"streaming_test\"\n",
    "streaming_collector = Online_Collector(streaming_table_name,ws=ws)\n",
    "\n",
    "import random\n",
    "streaming_collector.start_logging_df(buffer_time=2, batch_size=10)\n",
    "\n",
    "for run_id in [\"r000001\", \"r000002\", \"r000003\", \"r000004\", \"r000005\"]:\n",
    "    for i in range(1000):\n",
    "        for lr in [\"0.001\", \"0.002\"]:\n",
    "            df = pd.DataFrame({ \"timestamp\":pd.to_datetime('today'), \"lr\":[lr],\"metric1\":[random.uniform(3,50)] })\n",
    "            streaming_collector.stream_collect_df_queue(df)\n",
    "# streaming_collector.stop_logging()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nserafino\\AppData\\Local\\Temp\\ipykernel_115072\\1097353187.py:1: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>avg_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 days 00:00:00</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>-2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 days 00:00:00</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6 days 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 days 00:00:00</td>\n",
       "      <td>-9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10 days</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               day avg_temperature\n",
       "0  2 days 00:00:00             0.1\n",
       "1  0 days 00:00:00             0.5\n",
       "2  1 days 00:00:00           -2.25\n",
       "3  5 days 00:00:00             1.3\n",
       "4  6 days 00:00:00             1.0\n",
       "5  4 days 00:00:00            -9.5\n",
       "6          10 days       [1, 2, 3]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest = df.append(pd.Series(data=[\"10 days\", [1,2,3]], index=[\"day\", \"avg_temperature\"]), ignore_index=True)\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.avg_temperature.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categorical_feature</th>\n",
       "      <th>base_categorical_feature_value</th>\n",
       "      <th>base_dcount</th>\n",
       "      <th>period2</th>\n",
       "      <th>categorical_feature1</th>\n",
       "      <th>target_categorical_feature_value</th>\n",
       "      <th>target_dcount</th>\n",
       "      <th>basearraylength</th>\n",
       "      <th>targetarraylength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usaf</td>\n",
       "      <td>[711740,122260,749484,724673,722140,603900,584...</td>\n",
       "      <td>15</td>\n",
       "      <td>2013-04-13T00:00:00Z</td>\n",
       "      <td>usaf</td>\n",
       "      <td>[711740,722140,711740,225500,584570,747946,724...</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usaf</td>\n",
       "      <td>[711740,122260,749484,724673,722140,603900,584...</td>\n",
       "      <td>15</td>\n",
       "      <td>2013-05-13T00:00:00Z</td>\n",
       "      <td>usaf</td>\n",
       "      <td>[122260,749484,724673,603900,584570,722010,749...</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wban</td>\n",
       "      <td>[99999,99999,395,93009,93805,99999,99999,99999...</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-04-13T00:00:00Z</td>\n",
       "      <td>wban</td>\n",
       "      <td>[99999,93805,99999,99999,99999,12886,13733,395...</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wban</td>\n",
       "      <td>[99999,99999,395,93009,93805,99999,99999,99999...</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-05-13T00:00:00Z</td>\n",
       "      <td>wban</td>\n",
       "      <td>[99999,395,93009,99999,99999,12836,395,99999,9...</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  categorical_feature                     base_categorical_feature_value  \\\n",
       "0                usaf  [711740,122260,749484,724673,722140,603900,584...   \n",
       "1                usaf  [711740,122260,749484,724673,722140,603900,584...   \n",
       "2                wban  [99999,99999,395,93009,93805,99999,99999,99999...   \n",
       "3                wban  [99999,99999,395,93009,93805,99999,99999,99999...   \n",
       "\n",
       "   base_dcount               period2 categorical_feature1  \\\n",
       "0           15  2013-04-13T00:00:00Z                 usaf   \n",
       "1           15  2013-05-13T00:00:00Z                 usaf   \n",
       "2            8  2013-04-13T00:00:00Z                 wban   \n",
       "3            8  2013-05-13T00:00:00Z                 wban   \n",
       "\n",
       "                    target_categorical_feature_value  target_dcount  \\\n",
       "0  [711740,722140,711740,225500,584570,747946,724...             15   \n",
       "1  [122260,749484,724673,603900,584570,722010,749...             15   \n",
       "2  [99999,93805,99999,99999,99999,12886,13733,395...              8   \n",
       "3  [99999,395,93009,99999,99999,12836,395,99999,9...              8   \n",
       "\n",
       "   basearraylength  targetarraylength  \n",
       "0             1000                381  \n",
       "1             1000                619  \n",
       "2             1000                381  \n",
       "3             1000                619  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfread = pd.read_csv(\"C:/Users/nserafino/Downloads/export - 2022-05-05T140742.247.csv\")\n",
    "dfread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = dfread.shape[0]\n",
    "distance1 = []\n",
    "for i in range(n):\n",
    "    base_features = [int(x.strip(\"[\").strip(\"]\")) for x in dfread[\"base_categorical_feature_value\"][i].split(\",\")]\n",
    "    target_features = [int(x.strip(\"[\").strip(\"]\")) for x in dfread[\"target_categorical_feature_value\"][i].split(\",\")]\n",
    "    if len(target_features) > len(base_features):\n",
    "        target_features = random.sample(target_features, len(base_features))\n",
    "    elif len(target_features) < len(base_features):\n",
    "        base_features = random.sample(base_features, len(target_features))\n",
    "\n",
    "    distance1.append(distance.euclidean(target_features, base_features))\n",
    "    #     print(type(int(j.strip(\"[\").strip(\"]\"))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6295999.0974449795, 8439608.529132202, 1165274.6175211233, 1452404.0810938256]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x25ec82dfbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from monitoring.query import RT_Visualization\n",
    "rt_viz =RT_Visualization(streaming_table_name,ws)\n",
    "rt_viz.scatter(max_records=200, ago='12h',groupby='lr', y_metric='metric1',x_metric='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monitoring.query import KustoQuery\n",
    "query = KustoQuery(streaming_table_name, ws)\n",
    "\n",
    "query.anomaly_detection(min_t=\"4/26/2022 10:08:45\", max_t=\"4/23/2022 10:10:00\", step=\"0.5s\", metric=\"metric1\", agg=\"avg\", ts_col=\"timestamp\", groupby=\"lr\", sensitivity=0.1, filter=\"0.001\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monitoring.drift_analysis import Drift_Analysis\n",
    "drift_analysis =Drift_Analysis(ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = drift_analysis.analyze_drift(limit=30000000,base_table_name = 'ISDWeather',tgt_table_name='ISDWeather', base_dt_from='2013-04-13', base_dt_to='2014-05-13', tgt_dt_from='2013-04-13', tgt_dt_to='2014-05-13', bin='30d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>numeric_feature</th>\n",
       "      <th>wasserstein</th>\n",
       "      <th>base_min</th>\n",
       "      <th>base_max</th>\n",
       "      <th>base_mean</th>\n",
       "      <th>target_min</th>\n",
       "      <th>target_max</th>\n",
       "      <th>target_mean</th>\n",
       "      <th>categorical_feature</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>base_dcount</th>\n",
       "      <th>target_dcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-08 00:00:00+00:00</td>\n",
       "      <td>latitude</td>\n",
       "      <td>1.785103</td>\n",
       "      <td>-90</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>-90</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>usaf</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12320</td>\n",
       "      <td>11572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-08 00:00:00+00:00</td>\n",
       "      <td>latitude</td>\n",
       "      <td>1.785103</td>\n",
       "      <td>-90</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>-90</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>wban</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2404</td>\n",
       "      <td>2364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-08 00:00:00+00:00</td>\n",
       "      <td>longitude</td>\n",
       "      <td>12.042559</td>\n",
       "      <td>-179</td>\n",
       "      <td>999</td>\n",
       "      <td>-80</td>\n",
       "      <td>-179</td>\n",
       "      <td>999</td>\n",
       "      <td>-80</td>\n",
       "      <td>usaf</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12320</td>\n",
       "      <td>11572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-08 00:00:00+00:00</td>\n",
       "      <td>longitude</td>\n",
       "      <td>12.042559</td>\n",
       "      <td>-179</td>\n",
       "      <td>999</td>\n",
       "      <td>-80</td>\n",
       "      <td>-179</td>\n",
       "      <td>999</td>\n",
       "      <td>-80</td>\n",
       "      <td>wban</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2404</td>\n",
       "      <td>2364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-08 00:00:00+00:00</td>\n",
       "      <td>windSpeed</td>\n",
       "      <td>0.027431</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>usaf</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12320</td>\n",
       "      <td>11572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2013-06-12 00:00:00+00:00</td>\n",
       "      <td>year_1</td>\n",
       "      <td>0.867188</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>wban</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2404</td>\n",
       "      <td>2366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>2013-06-12 00:00:00+00:00</td>\n",
       "      <td>day_1</td>\n",
       "      <td>5.572159</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>usaf</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12320</td>\n",
       "      <td>11534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>2013-06-12 00:00:00+00:00</td>\n",
       "      <td>day_1</td>\n",
       "      <td>5.572159</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>wban</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2404</td>\n",
       "      <td>2366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2013-06-12 00:00:00+00:00</td>\n",
       "      <td>version_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>usaf</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12320</td>\n",
       "      <td>11534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>2013-06-12 00:00:00+00:00</td>\n",
       "      <td>version_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>wban</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2404</td>\n",
       "      <td>2366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    frequency numeric_feature  wasserstein  base_min  \\\n",
       "0   2014-04-08 00:00:00+00:00        latitude     1.785103       -90   \n",
       "1   2014-04-08 00:00:00+00:00        latitude     1.785103       -90   \n",
       "2   2014-04-08 00:00:00+00:00       longitude    12.042559      -179   \n",
       "3   2014-04-08 00:00:00+00:00       longitude    12.042559      -179   \n",
       "4   2014-04-08 00:00:00+00:00       windSpeed     0.027431         0   \n",
       "..                        ...             ...          ...       ...   \n",
       "415 2013-06-12 00:00:00+00:00          year_1     0.867188      2013   \n",
       "416 2013-06-12 00:00:00+00:00           day_1     5.572159         1   \n",
       "417 2013-06-12 00:00:00+00:00           day_1     5.572159         1   \n",
       "418 2013-06-12 00:00:00+00:00       version_1          0.0         1   \n",
       "419 2013-06-12 00:00:00+00:00       version_1          0.0         1   \n",
       "\n",
       "     base_max  base_mean  target_min  target_max  target_mean  \\\n",
       "0          87         40         -90          87           40   \n",
       "1          87         40         -90          87           40   \n",
       "2         999        -80        -179         999          -80   \n",
       "3         999        -80        -179         999          -80   \n",
       "4          90          3           0          79            3   \n",
       "..        ...        ...         ...         ...          ...   \n",
       "415      2014       2014        2013        2013         2013   \n",
       "416        31         14          12          30           21   \n",
       "417        31         14          12          30           21   \n",
       "418         1          1           1           1            1   \n",
       "419         1          1           1           1            1   \n",
       "\n",
       "    categorical_feature  euclidean  base_dcount  target_dcount  \n",
       "0                  usaf       28.0        12320          11572  \n",
       "1                  wban       28.0         2404           2364  \n",
       "2                  usaf       28.0        12320          11572  \n",
       "3                  wban       28.0         2404           2364  \n",
       "4                  usaf       28.0        12320          11572  \n",
       "..                  ...        ...          ...            ...  \n",
       "415                wban       28.0         2404           2366  \n",
       "416                usaf       28.0        12320          11534  \n",
       "417                wban       28.0         2404           2366  \n",
       "418                usaf       28.0        12320          11534  \n",
       "419                wban       28.0         2404           2366  \n",
       "\n",
       "[420 rows x 13 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n",
      "StartTime\n",
      "x_values  [0]\n",
      "y_values  [0]\n"
     ]
    }
   ],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "from monitoring.drift_analysis import Drift_Analysis\n",
    "drift_analysis =Drift_Analysis(ws)\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = JupyterDash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "tables_list = drift_analysis.list_tables()\n",
    "\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Tabs([\n",
    "        dcc.Tab(label='Dataset Drift', children=[\n",
    "               html.Div([\n",
    "\n",
    "        html.Div([\n",
    "            dcc.Dropdown(\n",
    "                tables_list,\n",
    "                tables_list[0],\n",
    "                id='table_option',\n",
    "            )]),\n",
    "            \n",
    "            html.Div([ dcc.Dropdown(\n",
    "                id='columns_option',\n",
    "                multi=True\n",
    "            )],),\n",
    "\n",
    "        ]),\n",
    "        dcc.Graph(id='graph_overview'),]),\n",
    "        dcc.Tab(label='Feature Analysis', children=[\n",
    "    html.Div([\n",
    "\n",
    "        html.Div([\n",
    "            dcc.Dropdown(\n",
    "                tables_list,\n",
    "                tables_list[0],\n",
    "                id='tables',\n",
    "            ),\n",
    "            dcc.DatePickerRange(\n",
    "            id='timeline',\n",
    "\n",
    "            ),\n",
    "            dcc.Store(id='intermediate-value')\n",
    "        ], style={'width': '20%', 'display': 'inline-block'}),\n",
    "\n",
    "        html.Div([ dcc.Dropdown(\n",
    "                id='columns'\n",
    "            ),\n",
    "\n",
    "        ], style={'width': '20%', 'float': 'right', 'display': 'inline-block'})\n",
    "    ]),\n",
    "\n",
    "    dcc.Graph(id='graph'),\n",
    "        ]),\n",
    "    ])\n",
    "\n",
    "])\n",
    "\n",
    "# overview tab\n",
    "@app.callback(\n",
    "    Output('columns_option', 'options'),\n",
    "    Input('table_option', 'value'))\n",
    "def set_columns_options(table_name):\n",
    "    return drift_analysis.list_table_columns(table_name)['AttributeName'].values\n",
    "\n",
    "@app.callback(\n",
    "    Output('columns_option', 'value'),\n",
    "    Input('columns_option', 'options'))\n",
    "def set_columns_value(available_options):\n",
    "    return available_options\n",
    "\n",
    "# feature analysis tab\n",
    "@app.callback(\n",
    "    Output('columns', 'options'),\n",
    "    Input('tables', 'value'))\n",
    "def set_columns_options(table_name):\n",
    "    return drift_analysis.list_table_columns(table_name)['AttributeName'].values\n",
    "\n",
    "@app.callback(\n",
    "    Output('columns', 'value'),\n",
    "    Input('columns', 'options'))\n",
    "def set_columns_value(available_options):\n",
    "    return available_options[0]\n",
    "@app.callback(\n",
    "    [Output('timeline', 'min_date_allowed'),Output('timeline', 'max_date_allowed'),Output('timeline', 'initial_visible_month'),Output('timeline', 'start_date'), Output('timeline', 'end_date')],\n",
    "    Input('tables', 'value'))\n",
    "def set_columns_options(table_name):\n",
    "    time_range =drift_analysis.get_time_range(table_name)\n",
    "\n",
    "    start_date = parser.parse(time_range[0]).replace(microsecond=0, second=0, minute=0)\n",
    "    end_date = parser.parse(time_range[1]).replace(microsecond=0, second=0, minute=0)\n",
    "    \n",
    "    return [start_date, end_date,end_date, start_date, end_date]\n",
    "@app.callback(\n",
    "    Output('intermediate-value', 'data'),\n",
    "    Input('tables', 'value'),\n",
    "    Input('timeline', 'start_date'),\n",
    "    Input('timeline', 'end_date'),     \n",
    "    )\n",
    "def calculate(table_name, start_date, end_date):\n",
    "\n",
    "    query_df = drift_analysis.analyze_drift(limit=100000,base_table_name = f'{table_name}',tgt_table_name=f'{table_name}', base_dt_from=f'{start_date}', base_dt_to=f'{end_date}', tgt_dt_from=f'{start_date}', tgt_dt_to=f'{end_date}', bin='30d')\n",
    "    # output = json.dumps({\"timestamp_col\":timestamp_col, \"data\":query_df.to_json(date_format='iso', orient='split')})\n",
    "    return query_df.to_json(date_format='iso', orient='split')\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('graph', 'figure'),\n",
    "    Input('columns', 'value'),\n",
    "    Input('intermediate-value', 'data')\n",
    "\n",
    "\n",
    "    )\n",
    "def update_figure(column,jsonified_cleaned_data):\n",
    "    # dff = pd.read_json(json.loads(jsonified_cleaned_data['data']), orient='split')\n",
    "    dff = pd.read_json(jsonified_cleaned_data, orient='split')\n",
    "    dff.sort_values(\"frequency\", inplace=True)\n",
    "    if dff[dff['numeric_feature']==column].shape[0]>0:\n",
    "        y_values = dff[dff['numeric_feature']==column]['wasserstein']\n",
    "        x_values= dff[dff['numeric_feature']==column][\"frequency\"]\n",
    "    elif dff[dff['categorical_feature']==column].shape[0]>0:\n",
    "        y_values = dff[dff['categorical_feature']==column]['target_dcount']\n",
    "\n",
    "        x_values = dff[dff['categorical_feature']==column][\"frequency\"]\n",
    "    else:\n",
    "        x_values =[0]\n",
    "        y_values =[0]\n",
    "    print(column)\n",
    "    print(\"x_values \", x_values)\n",
    "    print(\"y_values \", y_values)\n",
    "    fig = go.Figure([go.Scatter(x=x_values, y=y_values, name=f\"{column}\")])\n",
    "\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7f364c9551711cd4699acda32e0312c3edab483ae246bf330de758088cecccb"
  },
  "kernelspec": {
   "display_name": "dlresearch",
   "language": "python",
   "name": "dlresearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
