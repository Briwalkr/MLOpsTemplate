{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "kv=ws.get_default_keyvault()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prerequisite\n",
    "If you use the provision feature, then just need a workspace ws object\n",
    "If you need to create the cluster manually\n",
    "    1. Create a service principal and secret (SP)\n",
    "    2. Provision an ADX cluster and create a DB\n",
    "    3. Add the SP to be contributor of the cluster\n",
    "    4. pip install following packages: pip install --upgrade azure-mgmt-kusto azure-kusto-ingest azure-kusto-data azure-identity \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provisioning resource\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code provision ADX cluster and register neccessary information at the workspace's keyvault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option to set parameters to a custom ADX cluster\n",
    "# from monitoring import KV_SP_ID, KV_SP_KEY, KV_ADX_DB, KV_ADX_URI, KV_TENANT_ID\n",
    "# tenant_id = \"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "# #Application ID\n",
    "# client_id = \"af883abf-89dd-4889-bdb3-1ee84f68465e\"\n",
    "# #Client Secret, set it at your WS' keyvault with key name same as your client_id\n",
    "# client_secret = kv.get_secret(client_id)\n",
    "# subscription_id = \"0e9bace8-7a81-4922-83b5-d995ff706507\"\n",
    "\n",
    "# cluster_uri = \"https://adx02.westus2.kusto.windows.net\" #URL of the ADX Cluster\n",
    "# kv.set_secret(KV_SP_ID,client_id)\n",
    "# kv.set_secret(KV_SP_KEY,client_secret)\n",
    "# kv.set_secret(KV_ADX_DB,\"db01\")\n",
    "# kv.set_secret(KV_ADX_URI,cluster_uri)\n",
    "# kv.set_secret(KV_TENANT_ID,tenant_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monitoring.management import provision\n",
    "provision(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'ws'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nserafino\\Documents\\Other\\github-mlops\\GitHub\\src\\utilities\\test\\test.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000008?line=4'>5</a>\u001b[0m sample_pd_data[\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sample_pd_data[\u001b[39m'\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000008?line=5'>6</a>\u001b[0m sample_pd_data\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m'\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000008?line=7'>8</a>\u001b[0m online_collector \u001b[39m=\u001b[39m Online_Collector(table_name\u001b[39m=\u001b[39;49mtable_name,ws\u001b[39m=\u001b[39;49mws)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'ws'"
     ]
    }
   ],
   "source": [
    "from monitoring.data_collector import Online_Collector\n",
    "table_name = \"isd_weather_test4\" #new dataset\n",
    "\n",
    "sample_pd_data = pd.read_parquet(\"data/test_data.parquet\").head(10)\n",
    "sample_pd_data['timestamp'] = sample_pd_data['datetime']\n",
    "sample_pd_data.drop(['datetime'], inplace=True, axis=1)\n",
    "\n",
    "online_collector = Online_Collector(table_name=table_name,ws=ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_collector.cluster_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_collector.stream_collect_df(sample_pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_collector.batch_collect(sample_pd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Ingestion and Real Time Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'ws'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nserafino\\Documents\\Other\\github-mlops\\GitHub\\src\\utilities\\test\\test.ipynb Cell 15'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000013?line=0'>1</a>\u001b[0m \u001b[39m# Ingest streaming data  asynchronously with internal buffering mechanism to lower impact to main scoring thread\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000013?line=1'>2</a>\u001b[0m streaming_table_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstreaming_test\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000013?line=2'>3</a>\u001b[0m streaming_collector \u001b[39m=\u001b[39m Online_Collector(streaming_table_name,ws\u001b[39m=\u001b[39;49mws)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000013?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nserafino/Documents/Other/github-mlops/GitHub/src/utilities/test/test.ipynb#ch0000013?line=5'>6</a>\u001b[0m streaming_collector\u001b[39m.\u001b[39mstart_logging_df(buffer_time\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'ws'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ingest streaming data  asynchronously with internal buffering mechanism to lower impact to main scoring thread\n",
    "streaming_table_name=\"streaming_test\"\n",
    "streaming_collector = Online_Collector(streaming_table_name,ws=ws)\n",
    "\n",
    "import random\n",
    "streaming_collector.start_logging_df(buffer_time=2, batch_size=10)\n",
    "\n",
    "for run_id in [\"r000001\", \"r000002\", \"r000003\", \"r000004\", \"r000005\"]:\n",
    "    for i in range(1000):\n",
    "        for lr in [\"0.001\", \"0.002\"]:\n",
    "            df = pd.DataFrame({ \"timestamp\":pd.to_datetime('today'), \"lr\":[lr],\"metric1\":[random.uniform(3,50)] })\n",
    "            streaming_collector.stream_collect_df_queue(df)\n",
    "# streaming_collector.stop_logging()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monitoring.query import RT_Visualization\n",
    "rt_viz =RT_Visualization(streaming_table_name,ws)\n",
    "rt_viz.scatter(max_records=200, ago='12h',groupby='lr', y_metric='metric1',x_metric='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monitoring.query import KustoQuery\n",
    "query = KustoQuery(streaming_table_name, ws)\n",
    "\n",
    "query.anomaly_detection(min_t=\"4/26/2022 10:08:45\", max_t=\"4/23/2022 10:10:00\", step=\"0.5s\", metric=\"metric1\", agg=\"avg\", ts_col=\"timestamp\", groupby=\"lr\", sensitivity=0.1, filter=\"0.001\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monitoring.drift_analysis import Drift_Analysis\n",
    "drift_analysis =Drift_Analysis(ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_analysis.analyze_drift(limit=10000,base_table_name = 'ISDWeather',tgt_table_name='ISDWeather', base_dt_from='2013-04-13', base_dt_to='2014-05-13', tgt_dt_from='2013-04-13', tgt_dt_to='2014-05-13', bin='30d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = JupyterDash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "tables_list = drift_analysis.list_tables()\n",
    "\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "\n",
    "        html.Div([\n",
    "            dcc.Dropdown(\n",
    "                tables_list,\n",
    "                tables_list[0],\n",
    "                id='tables',\n",
    "            ),\n",
    "            dcc.Dropdown(\n",
    "                id='columns'\n",
    "            )\n",
    "        ], style={'width': '20%', 'display': 'inline-block'}),\n",
    "\n",
    "        html.Div([    dcc.DatePickerRange(\n",
    "        id='timeline',\n",
    "\n",
    "    ),\n",
    "\n",
    "        ], style={'width': '20%', 'float': 'right', 'display': 'inline-block'})\n",
    "    ]),\n",
    "\n",
    "    dcc.Graph(id='graph'),\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('columns', 'options'),\n",
    "    Input('tables', 'value'))\n",
    "def set_columns_options(table_name):\n",
    "    return drift_analysis.list_table_columns(table_name)['AttributeName'].values\n",
    "\n",
    "@app.callback(\n",
    "    Output('columns', 'value'),\n",
    "    Input('columns', 'options'))\n",
    "def set_columns_value(available_options):\n",
    "    return available_options[0]\n",
    "@app.callback(\n",
    "    [Output('timeline', 'min_date_allowed'),Output('timeline', 'max_date_allowed'),Output('timeline', 'initial_visible_month'),Output('timeline', 'end_date')],\n",
    "    Input('tables', 'value'))\n",
    "def set_columns_options(table_name):\n",
    "    time_range =drift_analysis.get_time_range(table_name)\n",
    "\n",
    "    start_date = parser.parse(time_range[0]).replace(microsecond=0, second=0, minute=0)\n",
    "    end_date = parser.parse(time_range[1]).replace(microsecond=0, second=0, minute=0)\n",
    "    \n",
    "    return [start_date, end_date,end_date, end_date]\n",
    "# @app.callback(\n",
    "#     Output('graph', 'figure'),\n",
    "#     Input('tables', 'value'),\n",
    "#     Input('columns', 'value'),\n",
    "#     Input('timeline', 'start_date'),\n",
    "#     Input('timeline', 'end_date')\n",
    "\n",
    "#     )\n",
    "# def update_figure(table, column, start_date, end_date):\n",
    "#     timestamp_col = drift_analysis.get_timestamp_col(table)\n",
    "#     if timestamp_col!=column:\n",
    "#         if start_date is not None:\n",
    "#             query =f\"{table}| where ['{timestamp_col}'] > datetime({start_date}) and ['{timestamp_col}'] <datetime({end_date})| summarize {column} =count({column}) by bin({timestamp_col}, 1d)\"\n",
    "#         else:\n",
    "#             query =f\"{table}| where ['{timestamp_col}'] <datetime({end_date})| summarize {column} =count({column}) by bin({timestamp_col}, 1d)\"\n",
    "#         filtered_df = drift_analysis.query(query)\n",
    "#         print(query)\n",
    "\n",
    "\n",
    "#         fig = go.Figure([go.Scatter(x=filtered_df[column].values, y=filtered_df[timestamp_col].values, name=f\"{column}\")])\n",
    "\n",
    "\n",
    "#         return fig\n",
    "\n",
    "\n",
    "app.run_server(mode='inline', debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7f364c9551711cd4699acda32e0312c3edab483ae246bf330de758088cecccb"
  },
  "kernelspec": {
   "display_name": "dlresearch",
   "language": "python",
   "name": "dlresearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
